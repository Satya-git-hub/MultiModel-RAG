{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "%pip install -r requirements.txt\n",
    "%pip install git+https://github.com/openai/CLIP.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv \n",
    "load_dotenv()\n",
    "key = os.getenv(\"key\")\n",
    "# os.environ[\"IMAGEIO_FFMPEG_EXE\"] = \"/usr/bin/ffmpeg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from moviepy.editor import VideoFileClip\n",
    "from pathlib import Path\n",
    "import speech_recognition as sr\n",
    "from pytube import YouTube\n",
    "from pprint import pprint\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_url=\"https://youtu.be/3dhcmeOTZ_Q\"\n",
    "output_video_path = \"content/video_data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from the video collect images,audio,text\n",
    "output_folder = \"content/mixed_data/\"\n",
    "output_audio_path = \"content/mixed_data/output_audio.wav\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = output_video_path + \"input_vid.mkv\"\n",
    "filepath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download the video \n",
    "import yt_dlp\n",
    "\n",
    "def download_video(url, output_path):\n",
    "    ydl_opts = {\n",
    "        'outtmpl': output_path + '/input_vid.mkv',  # Path where to save\n",
    "    }\n",
    "\n",
    "    with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
    "        result = ydl.extract_info(url, download=True)\n",
    "    \n",
    "    metadata = {\n",
    "        \"Author\": result.get(\"uploader\", \"Unknown\"),\n",
    "        \"Title\": result.get(\"title\", \"Unknown Title\"),\n",
    "        \"Views\": result.get(\"view_count\", \"Unknown Views\"),\n",
    "    }\n",
    "    \n",
    "    return metadata\n",
    "\n",
    "metadata_vid = download_video(video_url, output_video_path)\n",
    "metadata_vid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting video to image\n",
    "def video_to_image(video_path, output_folder):\n",
    "    clip = VideoFileClip(video_path)\n",
    "    clip.write_images_sequence(\n",
    "        os.path.join(output_folder, \"frame%04d.png\"), fps = 0.2\n",
    "    )\n",
    "\n",
    "video_to_image(filepath, output_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting video to audio \n",
    "def video_to_audio(video_path, output_audio_path):\n",
    "    clip = VideoFileClip(video_path)\n",
    "    audio = clip.audio\n",
    "    audio.write_audiofile(output_audio_path)\n",
    "\n",
    "video_to_audio(filepath, output_audio_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting audio to text \n",
    "def audio_to_text(audio_path):\n",
    "    recogizer = sr.Recognizer()\n",
    "    audio = sr.AudioFile(audio_path)\n",
    "\n",
    "    with audio as source:\n",
    "        audio_data = recogizer.record(source)\n",
    "\n",
    "        try:\n",
    "            # recognize the speech\n",
    "            text= recogizer.recognize_whisper(audio_data)\n",
    "        except sr.UnknownValueError:\n",
    "            print(\"Speech recognition could not understand teh audio\")\n",
    "    return text\n",
    "\n",
    "text_data = audio_to_text(output_audio_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(output_folder + \"output_text.txt\", \"w\") as file:\n",
    "    file.write(text_data)\n",
    "\n",
    "print(\"Text data saved to the file.\")\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MultiModel RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.indices import MultiModalVectorStoreIndex\n",
    "from llama_index.core import SimpleDirectoryReader\n",
    "from llama_index.core import StorageContext\n",
    "from llama_index.vector_stores.lancedb import LanceDBVectorStore\n",
    "import lancedb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_store = LanceDBVectorStore(uri = \"lancedb\", table_name=\"text_collection\")\n",
    "image_store = LanceDBVectorStore(uri = \"lancedb\", table_name=\"image_collection\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "storage_context = StorageContext.from_defaults(vector_store=text_store, image_store=image_store)\n",
    "documents = SimpleDirectoryReader(output_folder).load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = MultiModalVectorStoreIndex.from_documents(documents, storage_context=storage_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever_engine = index.as_retriever(similarity_top_k = 1, image_similarity_top_k = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.response.notebook_utils import display_source_node\n",
    "from llama_index.core.schema import ImageNode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve(retriever_engine, query_str):\n",
    "    retrieval_results = retriever_engine.retrieve(query_str)\n",
    "\n",
    "    retrieved_image = []\n",
    "    retrieval_text = []\n",
    "    for res_node in retrieval_results:\n",
    "        if isinstance(res_node.node, ImageNode):\n",
    "            retrieved_image.append(res_node.node.metadata[\"file_path\"])\n",
    "        else:\n",
    "            display_source_node(res_node, source_length=200)\n",
    "            retrieval_text.append(res_node.text)\n",
    "\n",
    "    return retrieved_image, retrieval_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"can you tell me what is linear regression? Explain equation of multiple linear regression?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img, text = retrieve(retriever_engine, query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def plot_images(images_path):\n",
    "  images_shown = 0\n",
    "  plt.figure(figsize=(16, 9))\n",
    "  for img_path in images_path:\n",
    "        if os.path.isfile(img_path):\n",
    "            image = Image.open(img_path)\n",
    "\n",
    "            plt.subplot(2, 3, images_shown + 1)\n",
    "            plt.imshow(image)\n",
    "            plt.xticks([])\n",
    "            plt.yticks([])\n",
    "\n",
    "            images_shown += 1\n",
    "            if images_shown >= 5:\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_images(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "metadata_str=json.dumps(metadata_vid)\n",
    "query_str = \"Tell me the equation linear regression?\"\n",
    "context_str = \"\".join(text)\n",
    "\n",
    "qa_tmpl_str=(\n",
    "    \"Based on the provided information, including relevant images and retrieved context from the video, \\\n",
    "    accurately and precisely answer the query without any additional prior knowledge.\\n\"\n",
    "\n",
    "    \"---------------------\\n\"\n",
    "    \"Context: {context_str}\\n\"\n",
    "    \"Metadata for video: {metadata_str} \\n\"\n",
    "\n",
    "    \"---------------------\\n\"\n",
    "    \"Query: {query_str}\\n\"\n",
    "    \"Answer: \"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.multi_modal_llms.openai import OpenAIMultiModal\n",
    "\n",
    "image_documents = SimpleDirectoryReader( input_files=img).load_data()\n",
    "openai_mm_llm = OpenAIMultiModal(model=\"gpt-4-vision-preview\", api_key=key, max_new_tokens=1500)\n",
    "\n",
    "\n",
    "result=openai_mm_llm.complete(\n",
    "    prompt=qa_tmpl_str.format(\n",
    "        query_str=query_str,metadata_str=metadata_str, context_str=context_str\n",
    "    ),\n",
    "    image_documents=image_documents,\n",
    ")\n",
    "    \n",
    "pprint(result.text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
